---
title: "Thesis' Script"
author: "Felipe Ferreira de Oliveira Rocha"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

## 1 About, Packages, and Options

This is to assure proper levels of replication regarding the thesis of Felipe Ferreira de Oliveira Rocha. For more details and information, please, contact: rocha.felipeferreira@gmail.com. 
 
For starters, I used the following packages (for which I am really grateful): 

```{r packages}

library(quanteda)
library(readtext)
library(quanteda.textmodels)
library(tidyverse)
library(lubridate)
library(patchwork)
library(tidytext)
library(here)
library(countrycode)
library(maps)
library(ggthemes)
library(igraph)
library(ggraph)
library(scales)
library(cartography)
library(gwordtree)
library(dendextend)
library(ggrepel)
library(FactoMineR)
library(factoextra)

```

Also, I defined a specific aesthetic function: 

```{r aesthetic_function}

thesis_theme <- function(){
  theme(axis.title = element_text(size = rel(1.2), colour = "black", face = "bold.italic"), axis.text = element_text(size = rel(1.2), colour = "black"), axis.ticks = element_blank(), legend.text = element_text(size = rel(1.2)), legend.title = element_blank())
}

```


## 2 Data source and Variables

Data source 

```{r data_source}

corpus_data_source <- readtext(file = here::here("corpus", "resenha de PEB", "corpus_1995_2019", "*.txt"), docvarsfrom = "filenames", docvarnames = c("position", "speaker", "date", "language", "city", "country", "continent", "type")) 
  
```

Adding and Fixing Variables

```{r adding_fixing_variables}

corpus_data_source$text <- str_squish(corpus_data_source$text) #ver

corpus_data_source$position <- as_factor(corpus_data_source$position)

corpus_data_source$realm <- ifelse(corpus_data_source$country != "brasil", 1, 0) %>% 
  factor(., levels = c(0, 1), labels = c("domestic", "international"))

corpus_data_source$speaker <- factor(corpus_data_source$speaker, levels = c("FHC", "L.F.Lampreia", "C.Lafer", "LULA", "C.Amorim", "DILMA", "A.Patriota", "L.A.Figueredo", "M.Vieira", "J.Serra", "A.Nunes", "E.Araujo"), labels = c("FHC", "Lampreia", "Lafer", "Lula", "Amorim", "Dilma", "Patriota", "Figueiredo", "Vieira", "Serra", "Nunes", "Araújo"))

corpus_data_source$language <- as_factor(corpus_data_source$language)

corpus_data_source$city <- as_factor(corpus_data_source$city)

corpus_data_source$country <- as_factor(corpus_data_source$country)

corpus_data_source$continent <- as_factor(corpus_data_source$continent)

corpus_data_source$date <- dmy(corpus_data_source$date)

corpus_data_source$year <- year(corpus_data_source$date)

corpus_data_source$type <- str_remove_all(corpus_data_source$type, "\\*")

corpus_data_source$type <- as_factor(corpus_data_source$type)

corpus_data_source$dyads <- ifelse(corpus_data_source$date < "2001-01-28", "FHC and Lampreia", ifelse(corpus_data_source$date >= "2001-01-29" & corpus_data_source$date < "2003-01-01", "FHC and Lafer", ifelse(corpus_data_source$date >= "2003-01-01" & corpus_data_source$date <= "2010-12-31", "Lula and Amorim", ifelse(corpus_data_source$date >= "2011-01-01" & corpus_data_source$date < "2013-08-26", "Dilma and Patriota", ifelse(corpus_data_source$date >="2013-08-28" & corpus_data_source$date < "2015-01-01", "Dilma and Figueiredo", ifelse(corpus_data_source$date >= "2015-01-02" & corpus_data_source$date < "2016-05-13", "Dilma and Vieira", ifelse(corpus_data_source$date >= "2016-05-13" & corpus_data_source$date <= "2017-02-22", "Temer and Serra", ifelse(corpus_data_source$date > "2017-02-22" & corpus_data_source$date < "2019-01-02", "Temer and Nunes", "Bolsonaro and Araújo"))))))))

# Fixing mistakes:

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_C.Lafer_26.01.2001_pt_sao.paulo_brasil_america_entrevista.txt"] <- "FHC and Lafer"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_C.Amorim_02.01.2011_pt_brasilia_brasil_america_discurso.txt"] <- "Lula and Amorim"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_A.Patriota_28.08.2013_pt_brasilia_brasil_america_discurso.txt"] <- "Dilma and Patriota"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_A.Patriota_28.08.2013_pt_brasilia_brasil_america_discurso*.txt"] <- "Dilma and Patriota"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_A.Patriota_29.08.2013_pt_brasilia_brasil_america_discurso.txt"] <- "Dilma and Patriota"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_A.Patriota_29.08.2013_pt_brasilia_brasil_america_discurso*.txt"] <- "Dilma and Patriota"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_M.Vieira_18.05.2016_pt_brasilia_brasil_america_discurso.txt"] <- "Dilma and Vieira"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_M.Vieira_26.06.2016_esp_varios_varios_america_artigo.txt"] <- "Dilma and Vieira"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_J.Serra_07.03.2017_pt_brasilia_brasil_america_discurso.txt"] <- "Temer and Serra"

corpus_data_source$dyads[corpus_data_source$doc_id == "MRE_A.Nunes_02.01.2019_pt_brasilia_brasil_america_discurso.txt"] <- "Temer and Nunes"

corpus_data_source$dyads <- as_factor(corpus_data_source$dyads)

# Done fixing the mistakes!

corpus_data_source$term_office_presid <- ifelse(corpus_data_source$date < "1999-01-01", "FHC1", ifelse(corpus_data_source$date >= "1999-01-01" & corpus_data_source$date < "2003-01-01", "FHC2", ifelse(corpus_data_source$date >= "2003-01-01" & corpus_data_source$date < "2007-01-01", "Lula1", ifelse(corpus_data_source$date >= "2007-01-01" & corpus_data_source$date < "2011-01-01", "Lula2", ifelse(corpus_data_source$date >= "2011-01-01" & corpus_data_source$date < "2015-01-01", "Dilma1", ifelse(corpus_data_source$date >= "2015-01-02" & corpus_data_source$date <= "2016-05-02", "Dilma2", ifelse(corpus_data_source$date > "2016-05-02" & corpus_data_source$date < "2019-01-02", "Temer", "Bolsonaro")))))))

# Fixing mistakes: 

corpus_data_source$term_office_presid[corpus_data_source$doc_id == "MRE_A.Nunes_02.01.2019_pt_brasilia_brasil_america_discurso.txt"] <- "Temer"

corpus_data_source$term_office_presid[corpus_data_source$doc_id == "MRE_C.Amorim_02.01.2011_pt_brasilia_brasil_america_discurso.txt"] <- "Lula2"

corpus_data_source$term_office_presid[corpus_data_source$doc_id == "MRE_M.Vieira_26.06.2016_esp_varios_varios_america_artigo.txt"] <- "Dilma2"

# Done fixing the mistakes!

corpus_data_source$term_office_presid <- as_factor(corpus_data_source$term_office_presid)

corpus_data_source$diplomacy_as_profession <- ifelse(corpus_data_source$speaker == "Lampreia" | corpus_data_source$speaker == "Amorim" | corpus_data_source$speaker == "Patriota" | corpus_data_source$speaker == "Figueiredo" | corpus_data_source$speaker == "Vieira" | corpus_data_source$speaker == "Araújo", "Yes", ifelse(corpus_data_source$speaker == "Lafer" | corpus_data_source$speaker == "Serra" | corpus_data_source$speaker == "Nunes", "No", "Not the case")) %>% as_factor()

corpus_data_source$president_party <- ifelse(corpus_data_source$term_office_presid == "FHC1" | corpus_data_source$term_office_presid  == "FHC2", "PSDB", ifelse(corpus_data_source$term_office_presid  == "Lula1" | corpus_data_source$term_office_presid == "Lula2" | corpus_data_source$term_office_presid  == "Dilma1" | corpus_data_source$term_office_presid  == "Dilma2", "PT", ifelse(corpus_data_source$term_office_presid  == "Temer", "PMDB", "PSL*"))) %>% as_factor()

corpus_data_source$level_presid_diplomacy <- ifelse(corpus_data_source$term_office_presid == "FHC1" | corpus_data_source$term_office_presid == "FHC2", "Medium", ifelse(corpus_data_source$term_office_presid == "Lula1" | corpus_data_source$term_office_presid == "Lula2", "High", ifelse(corpus_data_source$term_office_presid == "Dilma1" |corpus_data_source$term_office_presid == "Dilma2" | corpus_data_source$term_office_presid == "Temer", "Low", "Not enough data"))) %>% as_factor()

corpus_data_source$speaker_reshaped <- corpus_data_source$speaker %>% as.character()

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "FHC" & corpus_data_source$date < "1999-01-01"] <- "FHC I"

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "FHC" & corpus_data_source$date >= "1999-01-01" & corpus_data_source$date < "2003-01-01"] <- "FHC II"

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "Lula" & corpus_data_source$date >= "2003-01-01" & corpus_data_source$date < "2007-01-01"] <- "Lula I"

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "Lula" & corpus_data_source$date >= "2007-01-01" & corpus_data_source$date < "2011-01-01"] <- "Lula II"

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "Amorim" & corpus_data_source$date >= "2003-01-01" & corpus_data_source$date < "2007-01-01"] <- "Amorim I"

corpus_data_source$speaker_reshaped[corpus_data_source$speaker == "Amorim" & corpus_data_source$date >= "2007-01-01" & corpus_data_source$date < "2011-01-01"] <- "Amorim II"

corpus_data_source$speaker_reshaped[corpus_data_source$doc_id == "MRE_C.Amorim_02.01.2011_pt_brasilia_brasil_america_discurso.txt"] <- "Amorim II"

```

## 3 Stopwords

```{r stopwords}

custom_stopwords_part1 <- c("fernando", "henrique", "cardoso", "luiz", "luíz", "felipe", "lampreia","celso", "lafer", "luiz", "nunes", "amorim", "inácio", "lula", "da", "silva", "dilma", "vana", "rousseff", "michel", "temer", "jair", "messias", "bolsonaro", "antonio", "aguiar", "patriota", "alberto", "figueiredo", "mauro", "vieira","josé", "serra", "aloysio", "nunes", "ferreira", "filho", "ernesto", "araújo", "cc", "v", "srs", "srªs", "ex.ª", "fh", "vossa", "desafo", "desafos", "enfm", "ext", "resenha", "resenhas", "de", "2O", "pol", "profssional", "profssionalismo", "s.paulo", "obrigada", "afrmação", "signifca", "cinegrafstas", "7º", "presidente", "presidenta", "reafrmamos", "swissinfo.ch", "conseqüências", "econômicocomercial", "específcas", "difculdades", "nw", "df", "also", "é", "brasil", "brazil",  "one", "well", "política", "externa", "brasileiro", "brasileira", "4.0", "2017-2018", "brasil-índia", "c.a", "cartacapital", "bomtempo", "nº", "fm", "sc", "mv", "trem", "ate", "ô", "pois", "algum", "coisa", "alguma", "algumas", "nenhum", "nenhuma", "sr", "brasil-união", "taças", "ai", "aí", "três", "vão", "vai", "dr", "n", "`	", "`", "ser", "estar", "é", "ora", "logo", "algum", "alguns", "alguma", "algumas", "apenas", "cada", "diante de", "apesar", "sendo", "quase", "aqui", "daqui", "demais", "embora", "aliás", "inclusive", "talvez", "embora", "tal", "tais", "muitas", "muita", "muitos", "muito", "assim", "sobretudo", "talvez", "primeiro", "segundo", "terceiro", "quarto", "quinto", "primeira", "segunda", "terceira", "quarta", "quinta", "então", "dessa", "dessas", "desse", "desses", "esse", "esses", "essa", "essas", "aquele", "aqueles", "aquela", "auqelas", "aquilo", "aquilos","deste", "destes", "desta", "destas", "certamente", "algum", "alguns", "pouco", "pouca", "poucos", "poucas", "ponto", "vamos", "vezes", "vez", "outro", "outros", "outra", "outras", "assim", "vou", "novo", "novos", "nova", "novas", "ano", "anos", "coisa", "coisas", "querer", "quero", "dentro", "próprio", "próprios", "própria", "próprias", "barato", "barata", "baratos", "baratas", "acho", "ver", "faz", "parte", "disse", "tudo", "ainda", "dizer", "agora", "adversamente", "descobrir", "descobriu", "ganhei", "lembrar", "importante", "gente", "possa", "ver", "partes", "dar", "queremos", "fazendo", "sempre", "nunca", "nessa", "nessas", "nesse", "nesses", "nisso", "ver", "todo", "todos", "tudo", "partir", "hoje", "grande", "dois", "agora", "sempre", "bem", "acho", "dar", "dia", "grandes", "além", "possível", "maneira", "todas", "toda", "onde", "portanto", "caso", "única", "únicas", "único", "únicos", "fato", "fatos", "tão", "duas", "neste", "nestes", "nestas", "nesta", "us", "lado", "toda", "qualquer", "quaisquer", "qual", "quais", "quando", "último", "últimos", "última", "últimas", "last", "year", "years", "find", "sabe", "claro", "quatro", "sim", "não", "bom", "maior", "maiores", "tempo", "disso", "daquela", "daquelas", "daquele", "daqueles", "dessa", "dessas", "desse", "desses", "modo", "maneira", "forma", "acreditar", "frequente", "frequentemente", "entendemos", "naturalmente", "precisamos", "longo", "fundamental", "comum", "especial", "importante", "obrigado", "obrigada", "muito", "muitos", "pouco", "poucos", "pouca", "poucas", "importância", "preciso", "menor", "menos", "exemplo", "exemplos", "por", "para", "pelo", "pela", "fim", "final", "finais", "época", "vista", "vistas", "momento", "melhor", "now", "caro", "caros", "significa", "formas", "nível", "verdade", "mil", "millones", "semi-acabado", "semi-acabados", "fzemos", "fscal", "primeiroministro", "fnanciamento", "fnanceira", "unica", "unicas", "unico", "unicos", "única", "únicas", "único", "únicos", "posso", "pays", "digamos", "ergo", "digo", "têm", "fzeram", "exemplificativa", "conseguinte", "há")
                       

custom_stopwords_part2 <- c("haver", "havia", "aconteçam", "pacífca", "lembrar-se", "senhor", "senhora", "senhores", "senhoras", "excelente", "excelentíssimo", "excelentíssima", "excelentíssimos", "excelentíssimas", "yes", "no", "ss", "porém", "fiz", "vir", "vinte", "ter", "ir", "frmemente", "embaixador", "embaixadores", "embaixadora", "embaixadoras", "compromitido", "querido", "queridos", "querida", "queridas", "companheiro", "companheira", "companheiros", "companheiras")

```

## 4 Corpus and Tokenizing 

Corpus: 

```{r corpus}

main_corpus <- corpus_data_source %>% corpus()
ndoc(main_corpus)

```

Tokens:

```{r tokens}

nomes_compostos <- c("instituto rio branco", "hugo chávez", "evo morales", "folha de são paulo", "reino unido", "universidade de oxford", "lyse doucet", "san tiago dantas", "samuel pinheiro guimarães", "colin powell", "bom dia", "nicanor duarte", "relações internacionais", "relações exteriores", "condoleeza rice", "honoris causa", "bertha lutz", "cristovam buarque", "ricardo ferraço", "mylton severiano", "alan garcía", "osmar chohf*", "carlos setti", "lehman brothers", "gazeta mercantil", "correio bra*iliense", "b*ris casoy", "lu** fara* monteiro", "jedrzzej bielecki", "s*rgio danese", "jeffrey jowell", "gilberto freyre", "george* chi*oti", "pascal lamy", "ru* barbosa", "joaqu*m nabuco", "paulo freire", "cristina kirchner", "antonio palocci", "união europ*ia", "nações unidas", "direitos humanos", "américa latina", "américa do sul", "presidência pro tempore", "meio ambiente", "nutritional security")

main_tokens <- tokens(main_corpus)

main_tokens <- tokens_compound(main_tokens, pattern = phrase(nomes_compostos), case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "assembl*ia", replacement = "assembleia", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "japones*", replacement = "japones*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "chines*", replacement = "chines*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(x = main_tokens, pattern = "menin*", replacement = "menin@", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(x = main_tokens, pattern = "acredit*", replacement = "acreditar*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(x = main_tokens, pattern = "poluent*", replacement = "poluente*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "senhor*", replacement = "senhor*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "ministr*", replacement = "ministr*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "empres*ri*", replacement = "empresári*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "plant*", replacement = "plant*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "país*", replacement = "país*", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "conflit*", replacement = "conflit*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "amig*", replacement = "amig@", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "id*ia", replacement = "ideia", valuetype = "glob", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "quer*", replacement = "querer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "pod*", replacement = "poder*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "deve*", replacement = "dever*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "gost*", replacement = "gostar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "diz*", replacement = "dizer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "diss*", replacement = "dizer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "faz*", replacement = "fazer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "transform*", replacement = "transformar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "entend*", replacement = "entender*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "levant*", replacement = "levantar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "arrum*", replacement = "arrumar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "acontec*", replacement = "acontecer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "destac*", replacement = "destacar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "convers*", replacement = "conversar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "sabe*", replacement = "saber*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "exist*", replacement = "existir*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "ergu*", replacement = "erguer*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "prova*", replacement = "provar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "aprend*", replacement = "aprender*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "compra*", replacement = "comprar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "constru*", replacement = "construir*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "setor*", replacement = "setor*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "problem*", replacement = "problema*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "membro*", replacement = "membro*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "pobre*", replacement = "pobre*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "socia*", replacement = "social*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = phrase("organização mundial do comércio"), replacement = "omc", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "iniciativ*", replacement = "iniciativa*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "necess*", replacement = "necessário/necessidade*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "precis*", replacement = "preciso*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "comercia*", replacement = "comercial*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "trabalh*", replacement = "trabalh*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "medid*", replacement = "medida*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "quest*", replacement = "questão*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "aprov*", replacement = "aprovar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "admira*", replacement = "admirar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "lembr*", replacement = "lembrar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "agrícol*", replacement = "agrícola*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "polític*", replacement = "polític*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "comunidad*", replacement = "comunidade*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "sociedad*", replacement = "sociedade*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "pens*", replacement = "pensar*", case_insensitive = TRUE)

main_tokens <- tokens_replace(main_tokens, pattern = "havia*", replacement = "havia*", case_insensitive = TRUE)


```

## 5 Executive: The 1st Dimension

### 5. 1 Proper Nouns

```{r proper_nouns}

proper_nouns <- main_corpus %>% tokens() %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part2, padding = TRUE)

proper_nouns <- tokens_select(proper_nouns,
                              pattern =  '^[A-Z]',
                              valuetype = 'regex',
                              case_insensitive = FALSE, 
                              padding = TRUE)

proper_nouns_ngram <- textstat_collocations(proper_nouns, min_count = 10, tolower = FALSE, size = 2) %>% as_tibble() %>% select(collocation, count)

proper_nouns_ngram$collocation <- str_to_title(proper_nouns_ngram$collocation)

proper_nouns_ngram <- proper_nouns_ngram %>% group_by(collocation) %>% 
  summarise(count = sum(count))

proper_nouns_ngram <- separate(data = proper_nouns_ngram, col = collocation, into = c("p1", "p2"), sep = " ")

proper_nouns_ngram_plot <- proper_nouns_ngram %>%
  filter(count > 55) %>% 
  graph_from_data_frame()

seta <- grid::arrow(type = "closed", length = unit(.12, "inches"))

set.seed(202438)
proper_nouns_plot <- ggraph(proper_nouns_ngram_plot, layout = "fr") + geom_edge_link(aes(edge_alpha = count), show.legend = FALSE, arrow = seta, end_cap = circle(.05, "inches")) +
  geom_node_point(size = 3, colour = "lightblue") + geom_node_text(aes(label = name), repel = TRUE) + theme_void()

# ggsave("G1_collocation_exec.png", proper_nouns_plot, height = 7.5, width = 11, dpi = 600)

```


### 5.2 Keyness for Realm (Bigrams)

```{r keyness_realm}

nomes_compostos_keyness_realm <- c("san tiago dantas", "samuel pinheiro guimarães", "instituto rio branco","fara monteiro")

realm_keyness <- main_corpus %>% tokens() %>% 
  tokens_tolower() %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part2, padding = TRUE) %>% 
  tokens_compound(pattern = phrase(nomes_compostos_keyness_realm), case_insensitive = TRUE) %>% 
  tokens_ngrams(n = 2, concatenator = " ")  

realm_keyness <- dfm(realm_keyness)

realm_keyness <- dfm_group(realm_keyness, groups = "realm")

realm_keyness <- textstat_keyness(realm_keyness, target = "international") 

realm_keyness_exec <- textplot_keyness(realm_keyness, 25)

realm_keyness_exec_plot <- realm_keyness_exec + thesis_theme() + 
  scale_x_continuous(expand = c(0,0), limits = c(-210, 250)) +
  scale_color_manual(labels = c("Internacional", "Doméstico"), values = c("darkblue", "gray")) 

# ggsave("G2_real_exec_keyness.png", realm_keyness_exec_plot, height = 7, width = 10, dpi = 600)

```


### 5.3 TFIDF for each Continent: 


```{r tfidf_continent}

feat_continent <- dfm(main_tokens, tolower = TRUE, 
                      remove_numbers = TRUE, remove_punct = TRUE, 
                      remove = c(stopwords(language = "portuguese"),
                                 stopwords(language = "english"), 
                                 stopwords(language = "french"),
                                 stopwords(language = "spanish"), 
                                 stopwords(language = "italian"), 
                                 custom_stopwords_part1, custom_stopwords_part2))

feat_continent <- dfm_group(feat_continent, groups = "continent") %>% 
  dfm_tfidf()

feat_continent <- tidy(feat_continent)
feat_continent$document <- str_to_upper(feat_continent$document)
feat_continent$document <- str_replace_all(feat_continent$document, pattern = "AFRICA", replacement = "ÁFRICA")
feat_continent$document <- str_replace_all(feat_continent$document, pattern = "ASIA", replacement = "ÁSIA")
feat_continent$document <- str_replace_all(feat_continent$document, pattern = "AMERICA", replacement = "AMÉRICA")


exec_tfidf_continent_plot <- feat_continent %>% group_by(document) %>% top_n(20) %>% ungroup() %>% 
  ggplot(aes(x = reorder_within(term, count, document), y = count, fill = document)) + geom_point(size = 3, show.legend = FALSE) +
  facet_wrap(~document, scales = "free", strip.position = "right") + coord_flip() +
  scale_x_reordered() +
  ylab("Frequência") + xlab("Termos") +
  theme(strip.text = element_text(size = rel(1.2), face = "bold"), panel.background = element_rect(fill = 'white', colour = 'black'), panel.grid.major.y = element_line(colour = "gray", linetype = "dashed"), panel.grid.major.x = element_blank(), strip.background = element_rect(colour = "black")) + thesis_theme()

# ggsave("G3_exec_tfidf_continent_plot.png", exec_tfidf_continent_plot, height = 7.2, width = 9.2, dpi = 600)

```


### 5.4 Main Features and Co-Occurrence

```{r main_feat_cor}

main_feat_cor <- dfm(main_tokens, tolower = TRUE, remove_punct = TRUE,
                         remove_numbers = TRUE, remove_symbols = TRUE, 
                         remove = c(stopwords(language = "portuguese"),
                                    stopwords(language = "english"),
                                    stopwords(language = "french"),
                                    stopwords(language = "italian"),
                                    stopwords(language = "spanish"),
                                    custom_stopwords_part1, custom_stopwords_part2))

main_feat_cor <- dfm_trim(main_feat_cor, min_termfreq = 100) 
main_feat_cor <- fcm(main_feat_cor)
feat_cor <- names(topfeatures(main_feat_cor, 100))
main_feat_cor <- fcm_select(main_feat_cor, pattern = feat_cor, case_insensitive = TRUE)

set.seed(123456)
network_main_feat_plot <- textplot_network(main_feat_cor, omit_isolated = FALSE, edge_alpha = .3, edge_color = "lightblue", vertex_labelsize = 5.6)

# ggsave("G4_network_exec.png", network_main_feat_plot, height = 7.5, width = 11, dpi = 600)

```


## 6 Position: The 2nd Dimension

### 6.1 Comparing Main Features of PRES and MRE

```{r compare_main_feat}

feat_position <- tokens_subset(main_tokens, language == "pt")

feat_position <- dfm(feat_position, tolower = TRUE, 
                      remove_numbers = TRUE, remove_punct = TRUE, 
                      remove = c(stopwords(language = "portuguese"),
                                 stopwords(language = "english"), 
                                 stopwords(language = "french"),
                                 stopwords(language = "spanish"), 
                                 stopwords(language = "italian"), 
                                 custom_stopwords_part1, custom_stopwords_part2))

feat_position <- dfm_group(feat_position, groups = "position")

feat_position <- tidy(feat_position)

feat_position <- mutate(feat_position, count = count/sum(count))

feat_position <- pivot_wider(feat_position, names_from = document, values_from = count)

names(feat_position) <- c("term", "Chanceler", "Presidente")

feat_position_comparison <- ggplot(feat_position, aes(x = Presidente, y = Chanceler)) + 
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = term), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format(accuracy = 0.0001)) +
  scale_y_log10(labels = percent_format(accuracy = 0.0001)) +
  geom_abline(color = "red") + thesis_theme() + 
  theme(panel.background = element_rect(fill = "NA", colour = "black"))

# ggsave("G1_feat_comparison_position.png", feat_position_comparison, height = 7.5, width = 11, dpi = 600)

```


### 6.2 Keyness for Position (Bigram)

```{r keyness_position}

nomes_compostos_keyness_position<- c("san tiago dantas", "fara monteiro")

position_keyness <- main_corpus %>% tokens() %>% 
  tokens_tolower() %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>%
  tokens_remove(custom_stopwords_part2, padding = TRUE) %>% 
  tokens_compound(pattern = phrase(nomes_compostos_keyness_position), case_insensitive = TRUE) %>% 
  tokens_ngrams(n = 2, concatenator = " ")  

position_keyness <- dfm(position_keyness)

position_keyness <- dfm_group(position_keyness, groups = "position")

position_keyness <- textstat_keyness(position_keyness, target = "PRES") 

speakers_keyness_plot <- textplot_keyness(position_keyness, 30) 

speakers_keyness_plot <- speakers_keyness_plot + thesis_theme() + 
  scale_x_continuous(expand = c(0,0), limits = c(-210, 300)) +
  scale_color_manual(labels = c("Presidente", "Chanceler"), values = c("darkblue", "gray"))

# ggsave("G2_cargo_keyness_plot.png", speakers_keyness_plot, height = 6, width = 11.5, dpi = 600)

```

### 6.3 Proper nouns for Position

```{r proper_nouns_position}

#Presidents

proper_nouns_presid <- main_corpus %>% tokens() %>% tokens_subset(position == "PRES")
  
ndoc(proper_nouns_presid)

proper_nouns_presid <- proper_nouns_presid %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part2, padding = TRUE) 


proper_nouns_presid <- tokens_select(proper_nouns_presid,
                              pattern =  '^[A-Z]',
                              valuetype = 'regex',
                              case_insensitive = FALSE, 
                              padding = TRUE)

proper_nouns_presid_trigram <- textstat_collocations(proper_nouns_presid, min_count = 5, tolower = FALSE, size = 3) %>% as_tibble() %>% select(collocation, count) 

proper_nouns_presid_trigram$collocation <- str_to_title(proper_nouns_presid_trigram$collocation)

proper_nouns_presid_trigram <- proper_nouns_presid_trigram %>% group_by(collocation) %>% summarise(count = sum(count))

proper_nouns_presid_trigram$speaker <- "PRES" %>% as_factor()

#Chancellors

proper_nouns_mre <- main_corpus %>% tokens() %>% tokens_subset(position == "MRE")

ndoc(proper_nouns_mre)

proper_nouns_mre <- proper_nouns_mre %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part2, padding = TRUE)

proper_nouns_mre <- tokens_select(proper_nouns_mre,
                                     pattern =  '^[A-Z]',
                                     valuetype = 'regex',
                                     case_insensitive = FALSE, 
                                     padding = TRUE)

proper_nouns_mre_trigram <- textstat_collocations(proper_nouns_mre, min_count = 5, tolower = FALSE, size = 3) %>% as_tibble() %>% select(collocation, count) 

proper_nouns_mre_trigram$collocation <- str_to_title(proper_nouns_mre_trigram$collocation)

proper_nouns_mre_trigram <- proper_nouns_mre_trigram %>% group_by(collocation) %>% 
  summarise(count = sum(count))

proper_nouns_mre_trigram$speaker <- "MRE" %>% as_factor()

# Comparing values

proper_nouns_tri_mre_pres_joint <- rbind(proper_nouns_mre_trigram, proper_nouns_presid_trigram)

proper_nouns_tri_mre_pres_joint <- proper_nouns_tri_mre_pres_joint %>% 
  filter(count > 5)

proper_nouns_cargo_plot <- ggplot(proper_nouns_tri_mre_pres_joint, aes(x = reorder(collocation, count), y = count, fill = speaker)) + 
  geom_line(aes(group = collocation), colour = "black") + 
  geom_point(size = 3, shape = 21) + 
  coord_flip() +
  scale_fill_manual(values = c("MRE" = "white", "PRES" = "black"), labels = c("Chanceler", "Presidente")) +
  theme(panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_line(colour = "gray50", linetype = "dotted"), 
        panel.background = element_blank()) +
  thesis_theme() + 
  xlab("Expressões (Trigrama)") + ylab("Frequência")

# ggsave("G3_cargo_ProperNouns_plot.png", proper_nouns_cargo_plot, height = 10, width = 10, dpi = 600)

```

### 6.4 Main Features and Co-Occurrence

Chancellors: 

```{r main-feat-cor-mre}

main_feat_mre_cor <- tokens_subset(main_tokens, position == "MRE")

ndoc(main_feat_mre_cor)

main_feat_mre_cor <- dfm(main_feat_mre_cor, tolower = TRUE, remove_punct = TRUE,
                         remove_numbers = TRUE, remove_symbols = TRUE, 
                         remove = c(stopwords(language = "portuguese"),
                                    stopwords(language = "english"),
                                    stopwords(language = "french"),
                                    stopwords(language = "italian"),
                                    stopwords(language = "spanish"),
                                    custom_stopwords_part1, custom_stopwords_part2))

main_feat_mre_cor <- dfm_trim(main_feat_mre_cor, min_termfreq = 100) 
main_feat_mre_cor <- fcm(main_feat_mre_cor)
feat_mre_cor <- names(topfeatures(main_feat_mre_cor, 100))
main_feat_mre_cor <- fcm_select(main_feat_mre_cor, pattern = feat_mre_cor, case_insensitive = TRUE)

set.seed(123456)
mre_network <- textplot_network(main_feat_mre_cor, omit_isolated = FALSE, edge_alpha = .3, edge_color = "lightblue", vertex_labelsize = 5.6) + ggtitle("CHANCELERES") + 
  theme(plot.title = element_text(face = "bold", colour = "red"))

```

Presidents: 

```{r main-feat-cor-pres}

main_feat_pres_cor <- tokens_subset(main_tokens, position == "PRES")
ndoc(main_feat_pres_cor)

main_feat_pres_cor <- dfm(main_feat_pres_cor, tolower = TRUE, remove_punct = TRUE,
                         remove_numbers = TRUE, remove_symbols = TRUE, 
                         remove = c(stopwords(language = "portuguese"),
                                    stopwords(language = "english"),
                                    stopwords(language = "french"),
                                    stopwords(language = "italian"),
                                    stopwords(language = "spanish"),
                                    custom_stopwords_part1, custom_stopwords_part2))

main_feat_pres_cor <- dfm_trim(main_feat_pres_cor, min_termfreq = 100) 
main_feat_pres_cor <- fcm(main_feat_pres_cor)
feat_pres_cor <- names(topfeatures(main_feat_pres_cor, 100))
main_feat_pres_cor <- fcm_select(main_feat_pres_cor, pattern = feat_pres_cor, case_insensitive = TRUE)

set.seed(123456)
pres_network <- textplot_network(main_feat_pres_cor, omit_isolated = FALSE, edge_alpha = .3, edge_color = "lightpink", vertex_labelsize = 5.6) + ggtitle("PRESIDENTES") + 
  theme(plot.title = element_text(face = "bold", colour = "red"))

```

Joining them.

```{r joining_mre_chancelor}

set.seed(123456)
joined_network <- pres_network + mre_network + plot_layout(nrow = 2)
joined_network

# ggsave("G4_cargo_network_plot.png", joined_network, height = 17, width = 11, dpi = 600)

```

### KWIC 

```{r kwic_brazil_defends}

#MRE
brazil_defends_mre <- corpus_subset(main_corpus, position == "MRE") %>% corpus_reshape(to = "sentences") 

brazil_defends_mre_kwic <- kwic(brazil_defends_mre, phrase("o brasil defende"), case_insensitive = TRUE, valuetype = "fixed", window = 20) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_defends_mre_kwic$merged <- paste(brazil_defends_mre_kwic$pre, brazil_defends_mre_kwic$keyword, brazil_defends_mre_kwic$post)

brazil_defends_mre_kwic$merged <- str_trim(brazil_defends_mre_kwic$merged)

gwordtree(word = brazil_defends_mre_kwic$merged, firstword = "brasil", width = 1200)

#Presidentes

brazil_defends_pres <- corpus_subset(main_corpus, position == "PRES") %>% corpus_reshape(to = "sentences") 

brazil_defends_pres_kwic <- kwic(brazil_defends_pres, phrase("o brasil defende"), case_insensitive = TRUE, valuetype = "fixed", window = 20) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_defends_pres_kwic$merged <- paste(brazil_defends_pres_kwic$pre, brazil_defends_pres_kwic$keyword, brazil_defends_pres_kwic$post)

brazil_defends_pres_kwic$merged <- str_trim(brazil_defends_pres_kwic$merged)

gwordtree(word = brazil_defends_pres_kwic$merged, firstword = "brasil", width = 1200)

```


```{r brazil_must/should}

#MRE

brazil_mustshould_mre <- corpus_subset(main_corpus, position == "MRE") %>% corpus_reshape(to = "sentences") 

brazil_mustshould_mre_kwic <- kwic(brazil_mustshould_mre, phrase("o brasil deve"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_mustshould_mre_kwic$merged <- paste(brazil_mustshould_mre_kwic$pre, brazil_mustshould_mre_kwic$keyword, brazil_mustshould_mre_kwic$post)

brazil_mustshould_mre_kwic$merged <- str_trim(brazil_mustshould_mre_kwic$merged)

gwordtree(word = brazil_mustshould_mre_kwic$merged, firstword = "brasil", width = 1200)

#Presidentes

brazil_mustshould_pres <- corpus_subset(main_corpus, position == "PRES") %>% corpus_reshape(to = "sentences") 

brazil_mustshould_pres_kwic <- kwic(brazil_mustshould_pres, phrase("o brasil deve"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_mustshould_pres_kwic$merged <- paste(brazil_mustshould_pres_kwic$pre, brazil_mustshould_pres_kwic$keyword, brazil_mustshould_pres_kwic$post)

brazil_mustshould_pres_kwic$merged <- str_trim(brazil_mustshould_pres_kwic$merged)

gwordtree(word = brazil_mustshould_pres_kwic$merged, firstword = "brasil", width = 1200)

```


```{r brazil_needs}

#Chanceleres
brazil_needs_mre <- corpus_subset(main_corpus, position == "MRE") %>% corpus_reshape(to = "sentences") 

brazil_needs_mre_kwic <- kwic(brazil_needs_mre, phrase("o brasil precisa"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_needs_mre_kwic$merged <- paste(brazil_needs_mre_kwic$pre, brazil_needs_mre_kwic$keyword, brazil_needs_mre_kwic$post)

brazil_needs_mre_kwic$merged <- str_trim(brazil_needs_mre_kwic$merged)

gwordtree(word = brazil_needs_mre_kwic$merged, firstword = "brasil", width = 1200)

#Presidentes

brazil_needs_pres <- corpus_subset(main_corpus, position == "PRES") %>% corpus_reshape(to = "sentences") 

brazil_needs_pres_kwic <- kwic(brazil_needs_pres, phrase("o brasil precisa"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

brazil_needs_pres_kwic$merged <- paste(brazil_needs_pres_kwic$pre, brazil_needs_pres_kwic$keyword, brazil_needs_pres_kwic$post)

brazil_needs_pres_kwic$merged <- str_trim(brazil_needs_pres_kwic$merged)

gwordtree(word = brazil_needs_pres_kwic$merged, firstword = "brasil", width = 1200)

```


```{r brazil_can}

#Chanceleres
brazil_can_mre <- corpus_subset(main_corpus, position == "MRE") %>% corpus_reshape(to = "sentences") 

brazil_can_mre_kwic <- kwic(brazil_can_mre, phrase("o brasil pode"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

#Presidentes
brazil_can_pres <- corpus_subset(main_corpus, position == "PRES") %>% corpus_reshape(to = "sentences") 

brazil_can_pres_kwic <- kwic(brazil_can_pres, phrase("o brasil pode"), case_insensitive = TRUE, valuetype = "fixed", window = 100000) %>% as.data.frame() %>% select(pre, keyword, post)

```

### 6.5 KWIC: Graph

```{r kwic_graph}

kwic_graph_df <- tibble(sentence = c("Necessidade", "Possibilidade", "Defesa", "Deveres"), valores_mre = c(23, 45, 22, 18), valores_pres = c(43, 87, 5, 10))

kwic_graph_df <- gather(kwic_graph_df, key = "Agentes", value = "valores", -sentence)

kwic_graph_df$sentence <- str_to_upper(kwic_graph_df$sentence)

wordtree_plot <- ggplot(kwic_graph_df, aes(x = sentence, y = valores)) +
  geom_line(aes(group = sentence)) +
  geom_label(aes(label = valores, fill = Agentes), size = 6) + 
  coord_flip() +
  thesis_theme() +
  theme(axis.text.x = element_blank(), 
        axis.title = element_blank(), 
        panel.background = element_rect(fill = "white", colour = "black")) +
  scale_fill_manual(values = c("valores_mre" = "gray75", "valores_pres" = "white"), labels = c("valores_mre" = "Chanceler", "valores_pres" = "Presidente")) 

# ggsave("wordtree_plot.png", wordtree_plot, dpi = 500, width = 8.5, height = 4.5)

```

### 6.6 Maps

```{r mapa menções}

countries_dict <- dictionary(file = here("data analysis", "results", "paises.yml"), format = "YAML")

## Presidentes

pres_countries <- main_corpus %>% tokens() %>% tokens_subset(position == "PRES") %>% dfm(tolower = TRUE, dictionary = countries_dict) %>% convert(to = "data.frame")

pres_countries$doc_id <- NULL

pres_countries <- gather(pres_countries) %>% group_by(key) %>% summarise(value = sum(value))

pres_countries$full_name <- countrycode(sourcevar = pres_countries$key, origin = "iso3c", destination = "country.name", nomatch = NULL)

mapa_pres <- map_data(map = "world")
mapa_pres <- filter(mapa_pres, region  != "Antarctica")

setdiff(mapa_pres$region, pres_countries$full_name)
setdiff(pres_countries$full_name, mapa_pres$region)

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "United States", "USA")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "United Kingdom", "UK")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Vatican City", "Vatican")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "São Tomé & Príncipe", "Sao Tome and Principe")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Palestinian Territories", "Palestine")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Antigua & Barbuda", "Antigua")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Bosnia & Herzegovina", "Bosnia and Herzegovina")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Myanmar (Burma)", "Myanmar")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "ROM", "Romania")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Czechia", "Czech Republic")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "TMP", "Timor-Leste")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Hong Kong SAR China", "China")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Macao SAR China", "China")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Congo - Brazzaville", "Republic of Congo")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Congo - Kinshasa", "Democratic Republic of the Congo")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Côte d’Ivoire", "Ivory Coast")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Eswatini", "Swaziland")

pres_countries$full_name <- str_replace_all(pres_countries$full_name, pattern = "Réunion", "Reunion")

setdiff(mapa_pres$region, pres_countries$full_name)
setdiff(pres_countries$full_name, mapa_pres$region)

pres_countries$perc <- pres_countries$value/sum(pres_countries$value)*100

mapa_pres <- left_join(mapa_pres, pres_countries, by = c("region" = "full_name"))

mapa_pres[is.na.data.frame(mapa_pres)] <- 0

hist(mapa_pres$perc)
quantile(mapa_pres$perc)
summary(mapa_pres$perc)

mapa_pres$valor_cat <- cut(mapa_pres$perc, breaks = c(0, 0.5, 1.5, 2.5, 5.5, 48.99), labels = c("0-0.5%", "0.5-1.5%", "1.5-2.5%", "2.5-5.5%", "> 5.5%") ,include.lowest = TRUE)

mapa_pres_plot <- ggplot(data = mapa_pres, aes(x = long, y = lat, group = group, fill = valor_cat)) +
  geom_polygon(colour = "black") + 
  coord_cartesian() + theme_void() +
  labs(fill = "Menções:") + 
  theme_map(base_size = 12) +
  scale_fill_manual(values = c("white", "gray90", "gray70", "gray30", "black"))
  
## MRE

mre_countries <- main_corpus %>% tokens() %>% tokens_subset(position == "MRE") %>% dfm(tolower = TRUE, dictionary = countries_dict) %>% convert(to = "data.frame")

mre_countries$doc_id <- NULL

mre_countries <- gather(mre_countries) %>% group_by(key) %>% summarise(value = sum(value))

mre_countries$full_name <- countrycode(sourcevar = mre_countries$key, origin = "iso3c", destination = "country.name", nomatch = NULL)

mapa_mre <- map_data(map = "world")
mapa_mre <- filter(mapa_mre, region  != "Antarctica")

setdiff(mapa_mre$region, mre_countries$full_name)
setdiff(mre_countries$full_name, mapa_mre$region)

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "United States", "USA")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "United Kingdom", "UK")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Vatican City", "Vatican")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "São Tomé & Príncipe", "Sao Tome and Principe")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Palestinian Territories", "Palestine")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Antigua & Barbuda", "Antigua")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Bosnia & Herzegovina", "Bosnia and Herzegovina")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Myanmar (Burma)", "Myanmar")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "ROM", "Romania")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Czechia", "Czech Republic")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "TMP", "Timor-Leste")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Hong Kong SAR China", "China")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Macao SAR China", "China")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Congo - Brazzaville", "Republic of Congo")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Congo - Kinshasa", "Democratic Republic of the Congo")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Côte d’Ivoire", "Ivory Coast")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Eswatini", "Swaziland")

mre_countries$full_name <- str_replace_all(mre_countries$full_name, pattern = "Réunion", "Reunion")

setdiff(mapa_mre$region, mre_countries$full_name)
setdiff(mre_countries$full_name, mapa_mre$region)

mre_countries$perc <- mre_countries$value/sum(mre_countries$value)*100

mapa_mre<- left_join(mapa_mre, mre_countries, by = c("region" = "full_name"))

mapa_mre[is.na.data.frame(mapa_mre)] <- 0

hist(mapa_mre$perc)
quantile(mapa_mre$perc)
summary(mapa_mre$perc)

mapa_mre$valor_cat <- cut(mapa_mre$perc, breaks = c(0, 0.5, 1.5, 2.5, 5.5, 42.99), labels = c("0-0.5%", "0.5-1.5%", "1.5-2.5%", "2.5-5.5%", "> 5.5%") ,include.lowest = TRUE)

mapa_mre_plot <- ggplot(data = mapa_mre, aes(x = long, y = lat, group = group, fill = valor_cat)) +
  geom_polygon(colour = "black") + 
  coord_cartesian() + theme_void() +
  labs(fill = "Menções:") + 
  theme_map(base_size = 12) +
  scale_fill_manual(values = c("white", "gray90", "gray70", "gray30", "black"))

# Saving

# ggsave(filename = "G12_mre_map.png", plot = mapa_mre_plot, height = 4.5, width = 9, dpi = 600)

# ggsave(filename = "G13_pres_map.png", plot = mapa_pres_plot, height = 4.5, width = 9, dpi = 600)

```


## 7 Agents: The 3rd Dimension

### 7.1 TFIDF of agents

```{r tfidf_agents}

dfm_specific_terms <- main_corpus %>% tokens() %>% 
  tokens_subset(language == "pt") %>% 
  tokens_tolower() %>% 
  tokens_remove('[\\p{P}\\p{S}]', valuetype = 'regex', padding = TRUE) %>%
  tokens_remove("[0-9]+", valuetype = "regex", padding = TRUE) %>% 
  tokens_remove(stopwords(language = "portuguese"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "english"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "spanish"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "french"), padding = TRUE) %>% 
  tokens_remove(stopwords(language = "italian"), padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part1, padding = TRUE) %>% 
  tokens_remove(custom_stopwords_part2, padding = TRUE) %>% 
  tokens_compound(pattern = phrase(nomes_compostos_keyness_realm), case_insensitive = TRUE) %>% 
  tokens_ngrams(n = 2, concatenator = " ")
  
dfm_specific_terms <- dfm_specific_terms %>% dfm() %>% dfm_group(groups = "speaker_reshaped") %>% dfm_tfidf()

specific_terms <- tidy(dfm_specific_terms)
specific_terms$document <- str_to_upper(specific_terms$document)
specific_terms$term <- str_to_lower(specific_terms$term)

specific_terms <- specific_terms %>% group_by(document) %>% slice_max(n = 15, with_ties = FALSE, order_by = count) %>% ungroup() 

specific_terms$document <- factor(specific_terms$document, ordered = TRUE, levels = c("FHC I", "FHC II", "LAMPREIA", "LAFER", "LULA I", "AMORIM I", "LULA II", "AMORIM II", "DILMA", "PATRIOTA", "FIGUEIREDO", "VIEIRA", "SERRA", "NUNES", "ARAÚJO"))

specific_terms_plot <- ggplot(specific_terms, aes(x=reorder_within(term, count, document), y=count, fill = document)) + geom_col(show.legend = FALSE, fill = "white", colour = "black") + facet_wrap(~document, scales = "free", nrow = 5) + coord_flip() + scale_x_reordered() + thesis_theme() + 
  theme(axis.title = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.grid.major.x = element_blank(),
        strip.text = element_text(size = rel(1.3)))

# ggsave("speakers_tfidf.png", specific_terms_plot, dpi = 900, width = 13, height = 15.5)

```

### 7.2 Similarity of Agents

```{r agent_similarity}

agents_similarity_tokens <- main_tokens %>% tokens_subset(language == "pt")

agents_similarity <- dfm(agents_similarity_tokens, tolower = TRUE, 
                          remove_punct = TRUE, remove_numbers = TRUE, 
                          remove_symbols = TRUE, remove_separators = TRUE,
                          remove = c(stopwords(language = "portuguese"), 
                                     custom_stopwords_part1, custom_stopwords_part2)) %>% dfm_wordstem(language = "portuguese")

agents_similarity <- dfm_trim(agents_similarity, sparsity = .98)

agents_similarity <- dfm_group(agents_similarity, groups = "speaker_reshaped") %>% dfm_weight(scheme = "prop")

agents_similarity <- textstat_dist(agents_similarity, margin = "documents", method = "euclidean")

agents_similarity_dend <- agents_similarity %>% as.dist() %>% hclust(method = "average") %>% as.dendrogram()

agents_similarity_dend_plot <- color_branches(agents_similarity_dend, k = 5) %>% set("branches_lwd", 2.5)

plot(agents_similarity_dend_plot, main = "", ylab = "", xlab = "", axes = TRUE, sub = "")

```

```{r correspondence analysis}

agents_ca_tokens <- main_tokens %>% tokens_subset(language == "pt")

agents_ca_dfm <- dfm(agents_ca_tokens, tolower = TRUE, 
                          remove_punct = TRUE, remove_numbers = TRUE, 
                          remove_symbols = TRUE, remove_separators = TRUE,
                          remove = c(stopwords(language = "portuguese"), 
                                     custom_stopwords_part1, custom_stopwords_part2)) %>% dfm_wordstem(language = "portuguese")

agents_ca_dfm <- dfm_trim(agents_ca_dfm, sparsity = .98)

agents_ca_dfm <- dfm_group(agents_ca_dfm, groups = "speaker_reshaped") %>% dfm_weight(scheme = "prop")

agents_ca_model <- textmodel_ca(agents_ca_dfm)

agents_ca_scale1d <- textplot_scale1d(agents_ca_model) + theme(axis.text = element_text(colour = "black", size = rel(1.2)), panel.grid.major = element_line(colour = "gray50")) + geom_point(size = 2) + ylab("Posição dos Emissores")

agents_ca_model_coefficients <- data.frame(dim1 = coef(agents_ca_model, doc_dim = 1)$coef_document, dim2 = coef(agents_ca_model, doc_dim = 2)$coef_document)

agents_ca_plot_2d <- ggplot(agents_ca_model_coefficients, aes(x = dim1, y=dim2)) + geom_label_repel(aes(label = rownames(agents_ca_model_coefficients))) + xlim(c(-2, 4)) + theme(panel.background = element_rect(fill = "white", colour = "black"), panel.grid.major = element_line(colour = "gray92"), axis.text = element_text(size = rel(1.1), colour = "black"))

agents_ca_plot_merged <- agents_ca_plot_2d + agents_ca_scale1d

# ggsave(filename = "agents_correspondence_analysis.png", plot = agents_ca_plot_merged, dpi = 500, width = 11, height = 4.5)

fviz_screeplot(agents_ca_model, addlabels = TRUE)

```


