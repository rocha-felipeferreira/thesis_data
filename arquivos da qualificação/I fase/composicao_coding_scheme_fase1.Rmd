---
title: "Composição do Coding Scheme [Fase 1]"
author: "Felipe Rocha"
output: 
  html_document:
    code_folding: hide
    toc: TRUE
    toc_float: TRUE

---

# 1. Sobre o Documento

O documento reúne todas as informações referentes à primeira etapa de criação, análise e modificação metodológica do coding scheme. Em caso de dúvidas, favor entrar em contato com: rocha.felipeferreira@gmail.com

# 2. Sobre os pacotes utilizados

Os seguintes pacotes foram utilizados para realizar as análises aqui demonstradas:

* ``` quanteda ```
* ``` readtext ```
* ``` tidyverse ```
* ``` lubridate ```

```{r pacotes, include=FALSE}

library(quanteda)
library(readtext)
library(tidyverse)
library(lubridate)
library(ggthemes)

```


# 3. Corpus Original e suas Variáveis 


```{r corpus}

tese_textos <- readtext("corpus 1995-2016/*.txt", docvarsfrom = "filenames", docvarnames = c("cargo", "emissor", "data", "idioma", "cidade", "pais", "continente", "sobre"))

tese_corpus <- corpus(tese_textos)

data <- tese_corpus[["data"]]
data$data <- dmy(data$data)
tese_corpus[["data"]] <- data$data
data$data <- year(data$data)
tese_corpus[["ano"]] <- data$data

cargo <- tese_corpus[["cargo"]]
cargo$cargo <- factor(cargo$cargo)
tese_corpus[["cargo"]] <- cargo$cargo

lugar_discurso <- tese_corpus[["pais"]]
lugar_discurso$lugar_disc <- ifelse(lugar_discurso$pais != "brasil", 1, 0) 
lugar_discurso$lugar_disc <- factor(lugar_discurso$lugar_disc, levels = c(0, 1), labels = c("doméstico", "internacional"))
tese_corpus[["lugar_disc"]] <- lugar_discurso$lugar_disc

emissor <- tese_corpus[["emissor"]]
emissor$emissor <-factor(emissor$emissor, levels = c("FHC", "L.F.Lampreia", "C.Lafer", "LULA", "C.Amorim", "DILMA", "A.Patriota", "L.A.Figueredo", "M.Vieira", "J.Serra"), labels = c("FHC", "Lampreia", "Lafer", "Lula", "Amorim", "Dilma", "Patriota", "Figueiredo", "Vieira", "Serra"))
tese_corpus[["emissor"]] <-emissor$emissor

idioma <-tese_corpus[["idioma"]]
idioma$idioma <- factor(idioma$idioma)
tese_corpus[["idioma"]] <- idioma$idioma

cidade <-tese_corpus[["cidade"]]
cidade$cidade <- factor(cidade$cidade)
tese_corpus[["cidade"]] <- cidade$cidade

pais <-tese_corpus[["pais"]]
pais$pais <- factor(pais$pais)
tese_corpus[["pais"]] <- pais$pais

continente <- tese_corpus[["continente"]]
continente$continente <- factor(continente$continente)
tese_corpus[["continente"]] <- continente$continente

pares <- tese_corpus[["data"]]
pares$pares <- ifelse(pares$data < "2001-01-28", "FHC e Lampreia", ifelse(pares$data >= "2001-01-29" & pares$data < "2003-01-01", "FHC e Lafer", ifelse(pares$data >= "2003-01-01" & pares$data <= "2010-12-31", "Lula e Amorim", ifelse(pares$data >= "2011-01-01" & pares$data < "2013-08-26", "Dilma e Patriota", ifelse(pares$data >="2013-08-28" & pares$data < "2015-01-01", "Dilma e Figueiredo", ifelse(pares$data >= "2015-01-02" & pares$data < "2016-05-13", "Dilma e Vieira", "Temer e Serra"))))))
pares$pares <- factor(pares$pares)
tese_corpus[["pares"]] <- pares$pares

mandato_presid <- tese_corpus[["data"]]
mandato_presid$mandato_presid <- ifelse(mandato_presid$data < "1999-01-01", "FHC1", ifelse(mandato_presid$data >= "1999-01-01" & mandato_presid$data < "2003-01-01", "FHC2", ifelse(mandato_presid$data >= "2003-01-01" & mandato_presid$data < "2007-01-01", "Lula1", ifelse(mandato_presid$data >= "2007-01-01" & mandato_presid$data < "2011-01-01", "Lula2", ifelse(mandato_presid$data >= "2011-01-01" & mandato_presid$data < "2015-01-01", "Dilma1", ifelse(mandato_presid$data >= "2015-01-02" & mandato_presid$data < "2016-05-13", "Dilma2", "Temer"))))))

mandato_presid$mandato_presid <- factor(mandato_presid$mandato_presid)
tese_corpus[["mandato_presid"]] <- mandato_presid$mandato_presid


partido_pres <- tese_corpus[["mandato_presid"]]
partido_pres$partido_pres <- ifelse(partido_pres$mandato_presid == "FHC1" | partido_pres$mandato_presid == "FHC2", "PSDB", ifelse(partido_pres$mandato_presid == "Lula1" | partido_pres$mandato_presid == "Lula2" | partido_pres$mandato_presid == "Dilma1" | partido_pres$mandato_presid == "Dilma2", "PT", ifelse(partido_pres$mandato_presid == "Temer", "PMDB", "Não se aplica")))
partido_pres$partido_pres <- factor(partido_pres$partido_pres)
tese_corpus[["partido_pres"]] <- partido_pres$partido_pres


diplo_carreira <- tese_corpus[["emissor"]]
diplo_carreira$diplo_carreira <- ifelse(diplo_carreira$emissor == "Lampreia" | diplo_carreira$emissor == "Amorim" | diplo_carreira$emissor == "Patriota" | diplo_carreira$emissor == "Figueiredo" | diplo_carreira$emissor == "Vieira", 1, ifelse(diplo_carreira$emissor == "Lafer" | diplo_carreira$emissor == "Serra", 0, "Não se aplica"))
diplo_carreira$diplo_carreira <- factor(diplo_carreira$diplo_carreira)
tese_corpus[["diplo_carreira"]] <- diplo_carreira$diplo_carreira


grau_diplo_pres <- tese_corpus[["mandato_presid"]]
grau_diplo_pres$grau_diplo_pres <- ifelse(grau_diplo_pres$mandato_presid == "FHC1" | grau_diplo_pres$mandato_presid == "FHC2", "Moderado", ifelse(grau_diplo_pres$mandato_presid == "Lula1" | grau_diplo_pres$mandato_presid == "Lula2", "Alto", ifelse(grau_diplo_pres$mandato_presid == "Dilma1" | grau_diplo_pres$mandato_presid == "Dilma2" | grau_diplo_pres$mandato_presid == "Temer", "Baixo", "Não se aplica")))

grau_diplo_pres$grau_diplo_pres <- factor(grau_diplo_pres$grau_diplo_pres)
tese_corpus[["grau_diplo_pres"]] <- grau_diplo_pres$grau_diplo_pres

rm(idioma, lugar_discurso, grau_diplo_pres, pais, pares, partido_pres, mandato_presid, continente, cargo, cidade, data, emissor, diplo_carreira)

tese_corpus_dfm <- summary(tese_corpus, n = 10000)
  
```


O corpus foi constituido de `r length(tese_corpus_dfm$Text)` discursos pronunciados por Presidentes e Chanceleres brasileiros entre `r min(tese_corpus_dfm$ano)` e `r max(tese_corpus_dfm$ano)`. Para maiores informaçoes sobre o mesmo, favor, consultar o documento referente aos descritivos do Corpus. De qualquer modo, convém relembrar quais são as suas principais variáveis.


```{r estrutura do corpus, paged.print=TRUE}

as.tibble(summary(tese_corpus, n = 12, showmeta = TRUE))


```


# 4. Montagem do Dicionário


Conforme prevista na parte metodológica do projeto da tese, a montagem e operacionalização das categorias de análise começaram através de um dicionário pré-existente (pois isso aumenta a validade e confiabilidade da alocação dos termos). Ele foi criado para o artigo de Vilela e Neiva (2011). De tal modo, o início da primeira fase consiste em incorporar o dicionário dos autores no R. Segue o dicionário: 


```{r dicionario 1}

dicionario_fase1 <- dictionary(list(instituições_internacionais = c("união europ*ia", "ue", "comunidade dos países de língua portuguesa", "cplp", "organização das nações unidas", "onu", "banco mundial", "organização dos estados americanos", "oea", "g7", "g8", "organização internacional do trabalho", "oit", "área de livre comércio das américas", "alca", "mercado comum do sul", "mercosul", "organização das nações unidas para a educação e cultura", "unesco", "fundo monetário internacional", "fmi", "fundo das nações unidas para a infância", "unicef", "organização mundial do comércio", "omc", "organização mundial da saúde", "oms", "instituições financeiras multilaterais", "comunidade ibero-americana", "governança global", "banco interamericano de desenvolvimento", "bid", "organização das nações unidas para agricultura e alimentação","fao", "programa das nações unidas para o desenvolvimento", "pnud", "associação latino-americana de integração", "aladi"), economia = c("economia", "inflação", "estabilidade financeira", "instabilidade financeira", "financeira", "comércio", "desenvolvimento econômico", "subsídio", "protecionismo", "barreira não tarifária", "tarifa", "investir", "indústria", "produto interno bruto", "pib", "agricultura","riqueza natural", "produção", "produtivo", "força de trabalho", "geração de renda","geração de emprego", "geração de postos de trabalho", "crise financeira", "crise econômica", "credor", "devedor", "privatizar", "empresa", "exploração econômica", "exploração capitalista", "monopólio", "barreira comercial", "banco", "super*vit",  "déficit", "orçamento", "exportação", "importação", "agroindústria", "agronegócio","agropecuária", "bndes", "mercado"), desigualdade_social = c("desigualdade", "igualdade", "combate à fome", "exclusão social", "inclusão social", "justiça social", "injustiça social", "pobre", "rico", "distribuição de renda", "proteção social", "indigência", "indigente", "miséria", "favela", "mst", "segregação", "programa social", "bolsa família", "bolsa escola", "bolsa renda", "bolsa alimentação", "vulneravel", "menos favorecidos", "universalização da educação", "universalização dos serviços públicos", "contra a fome"), meio_ambiente = c("proteção ambiental", "questão ambiental", "conservação ambiental", "ambiental", "aquecimento global", "desaquecimento do planeta", "quioto", "kyoto", "meio ambiente","emissão de gás", "efeito estufa", "combustível renovável", "biocombustível", "energia renovável", "energia limpa", "desmatar", "desmatamento",  "mudança de clima", "poluição", "carbono", "co2", "ecologia", "eco 92",  "eco92", "eco_92", "recurso hídrico", "agenda 21", "rio92", "rio 92", "ecossistema", "sustentável", "poluente", "amazônia", "floresta", "queimada"),  paz_seguranca_internacional = c("paz", "narcotráfico", "tráfico de drogas", "conflitos de fronteira", "conflitos fronteiriços", "fronteira", "terror militar", "guerra", "defesa internacional", "defesa do território", "conflito", "arma", "armas", "armada", "desarmar", "teste nuclear", "guerra nuclear", "bomba nuclear", "segurança nacional", "segurança internacional", "conselho de segurança"), direitos_humanos_democracia = c("direitos", "democracia", "xenofobia", "discriminação", "racismo", "justiça", "injustiças", "minoria étnica sexual", "minoria étnica racial", "emancipação do país", "emancipação política", "cidadania", "exploração sexual", "exploração do trabalho infantil"), cooperacao_internacional = c("cooperação", "parceria", "intercâmbio", "embrapa")))


```


# 5. Aleatorização da Amostra


Após ter operacionalizado o dicionário no R, a segunda etapa dessa primeira fase se trata de criar uma amostra aleatória dos `r length(tese_corpus_dfm$Text)` pronunciamentos. Nessa fase, como o dicionário de Vilela e Neiva está em português, serão selecionados apenas os discursos em português. Para tanto, o seguinte comando foi usado:

```{r amostra aleatória}

amostra_aleatoria <- corpus_subset(tese_corpus, idioma == "pt")

ndoc(amostra_aleatoria)

set.seed(1234)
amostra_aleatoria <- corpus_sample(amostra_aleatoria, 314)
ndoc(amostra_aleatoria)

rm(tese_corpus)
rm(tese_corpus_dfm)
rm(tese_textos)

```


```{r descritivos da amostra aleatória, include=FALSE}

descritivos_amostra <- summary(amostra_aleatoria, n = 314)

```


Convém informar de onde surgiu a ideia de se constituir uma amostra aleatória de `r length(descritivos_amostra$Text)` discursos. O tamanho da amostra foi calculado via calculadora online de [cálculo amostral](https://www.surveysystem.com/sscalc.htm). Nesse caso, definiu-se um "confidence level" de 95% e um "confidence interval" de 5 na população total de discursos. O cálculo resultou em uma amostra necessária de `r length(descritivos_amostra$Text)` pronunciamentos.

A partir da obtenção dessa amostra aleatória, é necessário saber as suas caracteristicas descritivas. Para isso, em primeiro lugar, segue um gráfico com a quantidade de discursos resultantes para os Presidentes e os Ministros de Relações Exteriores. 

```{r proporção por cargo, echo=FALSE, fig.align="center", fig.height=3.6, fig.width=5}

descritivos_amostra %>% select(cargo) %>% count(cargo) %>%
  ggplot(aes(x=cargo, y=n)) + geom_bar(stat = "identity", fill = "white", colour = "darkblue") + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1.3), colour = "black"))

```

Pelo que se percebe, a quantidade de discursos alocadas para cada um dos cargos não supervaloriza e nem subvaloriza nenhum dos atores em análise. Como há mais discursos presidenciais, naturalmente, a amostra coletou uma maior quantidade dos mesmos. De qualquer modo, tudo aleatóriamente. Outra informação que é preciso observar também é a quantidade de discursos que cada emissor possui e a quantidade por Par Presidente-Chanceler. Para ambas as informações, segue o gráfico abaixo. 


```{r proporção por par, fig.height=5, fig.width=6, fig.align="center", echo=FALSE}

descritivos_amostra %>% select(pares, cargo) %>% count(pares, cargo) %>% ggplot(aes(x=reorder(pares, n), y=n, fill = cargo)) + geom_bar(stat = "identity") + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1.3), colour = "black")) + coord_flip() + scale_fill_wsj()

```

Conforme esperado, a amostra aleatória representa bem a proporção original de discursos totais de cada um dos emissores. Assim, Lula e Celso Amorim são os que mais possuem dados coletados e Dilma e Figueiredo são os que menos possuem pronunciamentos na amostra aleatória. 


Com isso, é possível seguir em frente e aplicar o dicionário. Logicamente, para evitar vieses, os resultados de frequência serão apresentados em ambas escalas relativa e absoluta. 


# 6. Aplicação Quantitativa do Dicionário [Escala Absoluta]


```{r aplicacao quanti do dic1}

aplica_quanti_dic <- dfm(amostra_aleatoria, tolower = TRUE, dictionary = dicionario_fase1)

```


Tendo aplicado o dicionário, é possível verificar algumas informações iniciais. Primeiro, quais foram os temas mais mencionados por Presidentes e por Chanceleres? Primeiro, seguem os valores em escala absoluta:


```{r aplic dic1 temas por cargo valor abs, fig.align="center"}

temas_cargo_dfm <- dfm_group(aplica_quanti_dic, groups = "cargo") %>% convert(to = "data.frame")

temas_cargo_dfm <- gather(temas_cargo_dfm, value = "freq", key = "temas", -document)

ggplot(temas_cargo_dfm, aes(x=reorder(temas, freq), y= freq, fill = document)) + geom_col() + coord_flip() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1), colour = "black")) + scale_fill_wsj() + theme_wsj() + labs(fill = "")

```


É possível verificar que o dicionário aparenta possuir um comportamento adequado no Corpus. Como se vê, a categoria mais mencionada por Presidentes e Chanceleres foi economia. Em seguida, instituições internacionais. Aqui, Chanceleres falaram bem mais nessa categoria do que os Presidentes. Esses, por sua vez, falaram mais em termos de desigualdade social, meio ambiente e direitos humanos do que aqueles.


Tendo visto os achados por Cargo, é importante verificar como cada um dos emissores em seus Pares mencionaram as categorias dos dicionários. 

    
```{r aplic dic1 temas por par valor abs, fig.align="center"}

temas_par_dfm <- dfm_group(aplica_quanti_dic, groups = c("cargo", "pares")) %>% convert(to = "data.frame")

temas_par_dfm <- temas_par_dfm %>% separate(document, into = c("cargo", "par"), sep = "\\.")

temas_par_dfm <- gather(temas_par_dfm, value = "freq", key = "temas", - cargo, - par)

ggplot(temas_par_dfm, aes(x=reorder(temas, freq), y=freq, fill = cargo)) + geom_bar(stat = "identity") + coord_flip() + facet_wrap(~par, nrow = 2) + theme(axis.title = element_blank(), axis.text = element_text(colour = "black")) 

```
     
O gráfico dá conta de mostrar quais são as frequências de menções dos Presidentes e Chanceleres em cada uma das categorias do dicionário. A visualização está prejudicada em função da escala absoluta dos valores, isso deve ser corrigido com os números percentuais. Vejamos, então, a evolução temporal dessas menções. 

     
```{r aplic dic1 temas por data e par valor abs, fig.align="center"}

temas_data_dfm <- dfm_group(aplica_quanti_dic, groups = c("ano", "cargo")) %>% convert(to = "data.frame")
temas_data_dfm <- temas_data_dfm %>% separate(document, into = c("ano", "cargo"), sep = "\\.")
temas_data_dfm <- gather(temas_data_dfm, value = "freq", key = "temas", - cargo, - ano)

ggplot(temas_data_dfm, aes(x=ano, y=freq, group = cargo, colour = cargo)) + geom_line() + facet_wrap(~temas, nrow = 4) +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title = element_blank(), axis.text = element_text(colour = "black", size = rel(.9)))

```

Um modo mais fácil de visualizar distâncias entre os pares é através de um cálculo em que os valores dos MRE são diminuidos pelos valores dos Presidentes. Se o resultado do cálculo for zero, há uma congruência quantitativa perfeita. Se os valores forem positivos, o Presidente falou menos na categoria do que o Chanceler. Se negativos, ocorreu o inverso. Cabe lembrar que existem missing data em relação ao Presidente e, nesse caso, os valores de NA foram substituidos por 0

```{r aplic dic1 calculo congruencia abs, fig.align="center"}

temas_congruencia_dfm <- dfm_group(aplica_quanti_dic, groups = c("ano", "cargo")) %>% convert(to="data.frame")
temas_congruencia_dfm <- temas_congruencia_dfm %>% separate(document, into = c("ano", "cargo"), sep = "\\.")
temas_congruencia_dfm <- gather(temas_congruencia_dfm, value = "freq", key = "temas", - cargo, - ano)

temas_congruencia_dfm <- spread(temas_congruencia_dfm, key = cargo, value = freq, fill = "sem valor")

temas_congruencia_dfm$ano_asteriscado <- temas_congruencia_dfm$ano
temas_congruencia_dfm$ano_asteriscado <- ifelse(temas_congruencia_dfm$PRES == "sem valor", paste(temas_congruencia_dfm$ano, "*", sep = ""), temas_congruencia_dfm$ano)
temas_congruencia_dfm$PRES <- ifelse(temas_congruencia_dfm$PRES == "sem valor", 0, temas_congruencia_dfm$PRES)
temas_congruencia_dfm$PRES <- as.integer(temas_congruencia_dfm$PRES)
temas_congruencia_dfm$MRE <- as.integer(temas_congruencia_dfm$MRE)

temas_congruencia_dfm$congruencia <- temas_congruencia_dfm$MRE - temas_congruencia_dfm$PRES

ggplot(temas_congruencia_dfm, aes(x=ano_asteriscado, y=congruencia, group = temas)) + facet_wrap(~temas, nrow = 4) + geom_line() + geom_hline(yintercept = 0, colour = "red", linetype = "dashed") + theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title = element_blank(), axis.text = element_text(colour = "black", size = rel(.9)))

```

Com o seguinte gráfico, ficou mais fácil visualizar as informações sobre níveis de congruência. Por exemplo, o tema da desigualdade social praticamente se encaixa perfeitamente com a linha vermelha. Isso significa que a tendência era de presença equilibrada entre as menções do MRE e dos Presidentes. Por outro lado, os temas ligados às instituições internacionais e à economia varia muito mais significantemente. Fato que demonstra uma congruência menos estável. A próxima seção mostra os mesmos resultados, mas em escala percentual relativa.  

# 7. Aplicação Quantitativa do Dicionário [Escala Percentual]

Primeiro, quais foram os temas mais mencionados por Presidentes e por Chanceleres? Seguem os valores em escala percentual:


```{r aplic dic1 temas por cargo valor perc, fig.align="center"}

temas_cargo_dfm_perc <- dfm_group(aplica_quanti_dic, groups = "cargo") %>% convert(to = "data.frame")

temas_cargo_dfm_perc <- gather(temas_cargo_dfm_perc, value = "freq", key = "temas", -document)

fazer_perc <- select(descritivos_amostra, Tokens, cargo) %>%
  group_by(cargo) %>%
  summarize(Tokens = sum(Tokens))
temas_cargo_dfm_perc$fazer_perc <- ifelse(temas_cargo_dfm_perc$document == "MRE", 278481, 260654)
rm(fazer_perc)

temas_cargo_dfm_perc$perc <- temas_cargo_dfm_perc$freq/temas_cargo_dfm_perc$fazer_perc

ggplot(temas_cargo_dfm_perc, aes(x=reorder(temas, perc), y= perc, fill = document)) + geom_col() + coord_flip() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1), colour = "black")) + scale_fill_wsj() + theme_wsj() + labs(fill = "") + scale_y_continuous(labels = scales::percent)

```

É importante verificar como cada um dos emissores em seus Pares mencionaram as categorias dos dicionários. 

    
```{r aplic dic1 temas por par valor perc, fig.align="center"}

temas_par_dfm_perc <- dfm_group(aplica_quanti_dic, groups = c("cargo", "pares")) %>% convert(to = "data.frame")
  
temas_par_dfm_perc <- temas_par_dfm_perc %>% separate(document, into = c("cargo", "par"), sep = "\\.")
temas_par_dfm_perc <- gather(temas_par_dfm_perc, value = "freq", key = "temas", - cargo, - par)

fazer_perc <- select(descritivos_amostra, Tokens, pares) %>%
  group_by(pares) %>%
  summarize(Tokens = sum(Tokens))

temas_par_dfm_perc$fazer_perc <- ifelse(temas_par_dfm_perc$par == "Dilma e Figueiredo", 11805, ifelse(temas_par_dfm_perc$par == "Dilma e Patriota", 24090, ifelse(temas_par_dfm_perc$par == "FHC e Lafer", 66231, ifelse(temas_par_dfm_perc$par == "FHC e Lampreia", 99812, ifelse(temas_par_dfm_perc$par == "Lula e Amorim", 321451, 0)))))

temas_par_dfm_perc$perc <- temas_par_dfm_perc$freq/temas_par_dfm_perc$fazer_perc

rm(fazer_perc)

ggplot(temas_par_dfm_perc, aes(x=reorder(temas, perc), y=perc, fill = cargo)) + geom_bar(stat = "identity") + coord_flip() + facet_wrap(~par, nrow = 2, scales = "free_x") + theme(axis.title = element_blank(), axis.text = element_text(colour = "black")) + scale_y_continuous(labels = scales::percent)

```


Vejamos, agora, a evolução temporal dessas menções em escala percentual. 

     
```{r aplic dic1 temas por data e par valor perc, fig.align="center"}

temas_data_dfm_perc <- dfm_group(aplica_quanti_dic, groups = c("ano", "cargo")) %>% convert(to = "data.frame")
temas_data_dfm_perc <- temas_data_dfm_perc %>% separate(document, into = c("ano", "cargo"), sep = "\\.")
temas_data_dfm_perc <- gather(temas_data_dfm_perc, value = "freq", key = "temas", - cargo, - ano)

fazer_perc <- select(descritivos_amostra, Tokens, ano) %>%
  group_by(ano) %>%
  summarize(Tokens = sum(Tokens))

temas_data_dfm_perc$fazer_perc <- ifelse(temas_data_dfm_perc$ano == "1995", 11745, ifelse(temas_data_dfm_perc$ano == "1996", 26195, ifelse(temas_data_dfm_perc$ano == "1997", 6865, ifelse(temas_data_dfm_perc$ano == "1998", 15010, ifelse(temas_data_dfm_perc$ano == "1999", 10930, ifelse(temas_data_dfm_perc$ano == "2000", 25617, ifelse(temas_data_dfm_perc$ano == "2001", 48933, ifelse(temas_data_dfm_perc$ano == "2002", 20748, ifelse(temas_data_dfm_perc$ano == "2003", 41775, ifelse(temas_data_dfm_perc$ano == "2004", 36269, ifelse(temas_data_dfm_perc$ano == "2005", 52758, ifelse(temas_data_dfm_perc$ano == "2006", 46996, ifelse(temas_data_dfm_perc$ano == "2007", 31963, ifelse(temas_data_dfm_perc$ano == "2008", 23442, ifelse(temas_data_dfm_perc$ano == "2009", 48401, ifelse(temas_data_dfm_perc$ano == "2010", 39847, ifelse(temas_data_dfm_perc$ano == "2011", 13223, ifelse(temas_data_dfm_perc$ano == "2012", 13223, ifelse(temas_data_dfm_perc$ano == "2013", 3549, ifelse(temas_data_dfm_perc$ano == "2014", 8256, 0))))))))))))))))))))

rm(fazer_perc)

temas_data_dfm_perc$perc <- temas_data_dfm_perc$freq/temas_data_dfm_perc$fazer_perc


ggplot(temas_data_dfm_perc, aes(x=ano, y=perc, group = cargo, colour = cargo)) + geom_line() + facet_wrap(~temas, nrow = 4) +  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title = element_blank(), axis.text = element_text(colour = "black", size = rel(.9))) + scale_y_continuous(labels = scales::percent)

rm(temas_cargo_dfm)
rm(temas_cargo_dfm_perc)
rm(temas_congruencia_dfm)
rm(temas_data_dfm)
rm(temas_data_dfm_perc)
rm(temas_par_dfm)
rm(temas_par_dfm_perc)


```

Tendo visto como o dicionário responde em termos de análise centrada apenas em valores númericos (sejam percentuais ou absolutos). É necessário começar a fase de exploração textual com o objetivo de explorar e descobrir certos padrões e termos que precisam ser incorporados ou alterados em uma nova versão do dicionário, sendo esta uma versão final. 


# 8. Exploração Textual

Para começar a exploração textual, seguiremos os seguintes passos: 

1. Exploração Estrutural do Corpus
    + Mineração Textual Global
    + Topic Models
2. Exploração Categórica do Corpus
    + Mineração Textual de cada Categoria

Portanto, comecemos com uma exploração mais estrutural do Corpus


```{r exploracao textual visao estrutural TM global}

explor_text_dfm <- dfm(amostra_aleatoria, tolower = TRUE, remove = c(stopwords("portuguese"), "é", "the", "porque", "então"), remove_punct = TRUE, remove_numbers = TRUE)

explor_text_dfm <- dfm_wordstem(explor_text_dfm, language = "portuguese")

explor_text_dfm

explor_text_dfm <- dfm_trim(explor_text_dfm, min_docfreq = 0.01, max_docfreq = 0.99, docfreq_type = "prop")

explor_text_dfm

explor_text_dfm_tfidf <- dfm_tfidf(explor_text_dfm)


```


Primeiro, os termos mais repetidos no Corpus

```{r exploracao textual visao estrutural TM global - top}

textplot_wordcloud(explor_text_dfm, color = c("black", "red", "blue", "darkgreen"), max_words = 300, rotation = .25)

```


Agora, os termos específicos mais repetidos no Corpus

```{r exploracao textual visao estrutural TM global - top tfidf}

explor_text_top_feat <- textstat_frequency(explor_text_dfm_tfidf, n = 40)

ggplot(explor_text_top_feat, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, uma matriz de coocorrência:

```{r exploracao textual visao estrutural TM global - network}

coocorrencia <- dfm_trim(explor_text_dfm, min_termfreq = 300)
textplot_network(coocorrencia, omit_isolated = TRUE)

```

Outra forma de verificar variações lexicais é por meio de análise de collocations. 

```{r exploracao textual visao estrutural TM global - collocations}

collocations <- textstat_collocations(amostra_aleatoria, size = 5, min_count = 8, tolower = TRUE)

collocations <- as.data.frame(collocations)
collocations <- collocations[1:40,]

ggplot(collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```


Análise de nomes próprios mais repetidos

```{r exploracao textual visao estrutural TM global - nomes próprios}

nomes_prop <- tokens(amostra_aleatoria)
nomes_prop <- tokens_remove(nomes_prop, stopwords("portuguese"), padding = TRUE)
nomes_prop <- tokens_select(nomes_prop, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop <- textstat_collocations(nomes_prop, size = 3, tolower = FALSE)

nomes_prop <- nomes_prop[1:40,]

ggplot(nomes_prop, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```


Para finalizar essa visão mais estrutural, vejamos como uma modelagem baseada em Topic Models categorizaria as palavras da amostra textual. 


```{r exploracao textual visao estrutural TM global - topicmodels}

tm_explor <- dfm(amostra_aleatoria, tolower = TRUE, remove = c(stopwords("portuguese"), "é", "the", "porque", "então"), remove_punct = TRUE, remove_numbers = TRUE)
tm_explor <- dfm_wordstem(tm_explor, language = "portuguese")
tm_explor <- dfm_trim(tm_explor, min_termfreq = 0.95, termfreq_type = "quantile", max_docfreq = 0.3, docfreq_type = "prop")
tm_explor <- tm_explor[ntoken(tm_explor)>0, ]

require(topicmodels)

tm_explor <- convert(tm_explor, to = "topicmodels")
tm_modelo <- LDA(tm_explor, k =10)

terms(tm_modelo, 10)

```


Com isso, torna-se possível seguir adiante e realizar análises cujos focos estejam direcionados às categorias do dicionário. Isso será importante para que tenhamos uma dimensão sobre quais foram as palavras mais usadas no contexto de cada uma delas. Para tanto, serão explorados padrões lexicométricos de cada uma das categorias do dicionário, bem como geradas listas de KWIC para a análise contextual qualitativa das mesmas. 

No tocante aos padrões lexicométricos, veremos: a. Termos mais repetidos; b) Termos mais específicos (tfidf); c. Collocations; e, d. Nomes Próprios. No tocante ás listas de KWIC, serão montadas usando os mesmos parâmetros da construção do Corpus como aqui feito (window = 10). 

Comecemos, então, com a categoria referente às Instituições Internacionais. 


```{r exploracao textual visao categorica - inst internacionais}

inst.int <- tokens(amostra_aleatoria)
inst.int <- tokens_select(inst.int, pattern = dicionario_fase1[["instituições_internacionais"]], case_insensitive = TRUE, window = 10)

inst.int <- dfm(inst.int, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

inst.int <- dfm_wordstem(inst.int, language = "portuguese")
inst.int.tfidf <- dfm_tfidf(inst.int)

```

Aos padrões lexicométricos: 

Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - inst internacionais - termos repetidos}

textplot_wordcloud(inst.int, max_words = 300, rotation = .25)

```

Então, os termos mais específicos

```{r exploracao textual visao categorica - inst internacionais - termos especificos tfidf}

inst.int.especific <- textstat_frequency(inst.int.tfidf, n = 40) 

ggplot(inst.int.especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - inst internacionais - collocations}

inst_int_collocations <- tokens(amostra_aleatoria)
inst_int_collocations <- tokens_select(inst_int_collocations, pattern = dicionario_fase1[["instituições_internacionais"]], case_insensitive = TRUE, window = 10)

inst_inter_collocations <- textstat_collocations(inst_int_collocations, size = 4, min_count = 3, tolower = TRUE)

inst_inter_collocations <- as.data.frame(inst_inter_collocations)
inst_inter_collocations <- inst_inter_collocations[1:40,]

ggplot(inst_inter_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - inst internacionais - nomes próprios}

nomes_prop_inst.int <- tokens(amostra_aleatoria)
nomes_prop_inst.int <- tokens_select(nomes_prop_inst.int, pattern = dicionario_fase1[["instituições_internacionais"]], case_insensitive = TRUE, window = 10)

nomes_prop_inst.int <-tokens_remove(nomes_prop_inst.int, stopwords("portuguese"), padding = TRUE)

nomes_prop_inst.int <- tokens_select(nomes_prop_inst.int, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_inst.int <- textstat_collocations(nomes_prop_inst.int, size = 2, tolower = FALSE)

nomes_prop_inst.int <- nomes_prop_inst.int[1:40,]

ggplot(nomes_prop_inst.int, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - inst internacionais - kwic}

inst_inter_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["instituições_internacionais"]]), case_insensitive = TRUE, window = 10)

```

Agora, passemos para categoria "Economia": 


```{r exploracao textual visao categorica - economia}

economia <- tokens(amostra_aleatoria)
economia <- tokens_select(economia, pattern = dicionario_fase1[["economia"]], case_insensitive = TRUE, window = 10)

economia <- dfm(economia, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

economia <- dfm_wordstem(economia, language = "portuguese")
economia.tfidf <- dfm_tfidf(economia)

```

Primeiro, os termos mais repetidos: 

```{r exploracao textual visao categorica - economia - termos repetidos}

textplot_wordcloud(economia, max_words = 300, rotation = .25)

```

Então, os termos mais específicos

```{r exploracao textual visao categorica - economia - termos especificos tfidf}

economia.especific <- textstat_frequency(economia.tfidf, n = 40) 

ggplot(economia.especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - economia - collocations}

economia_collocations <- tokens(amostra_aleatoria)
economia_collocations <- tokens_select(economia_collocations, pattern = dicionario_fase1[["economia"]], case_insensitive = TRUE, window = 10)

economia_collocations <- textstat_collocations(economia_collocations, size = 4, min_count = 3, tolower = TRUE)

economia_collocations <- as.data.frame(economia_collocations)
economia_collocations <- economia_collocations[1:40,]

ggplot(economia_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - economia - nomes próprios}

nomes_prop_economia <- tokens(amostra_aleatoria)
nomes_prop_economia <- tokens_select(nomes_prop_economia, pattern = dicionario_fase1[["economia"]], case_insensitive = TRUE, window = 10)

nomes_prop_economia <-tokens_remove(nomes_prop_economia, stopwords("portuguese"), padding = TRUE)

nomes_prop_economia <- tokens_select(nomes_prop_economia, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_economia <- textstat_collocations(nomes_prop_economia, size = 2, tolower = FALSE)

nomes_prop_economia <- nomes_prop_economia[1:40,]

ggplot(nomes_prop_economia, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - economia - kwic}

economia_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["economia"]]), case_insensitive = TRUE, window = 10)

```

Agora, passemos para categoria "Desigualdade Social":

```{r exploracao textual visao categorica - desigualdade social}

desig_social <- tokens(amostra_aleatoria)
desig_social <- tokens_select(desig_social, pattern = dicionario_fase1[["desigualdade_social"]], case_insensitive = TRUE, window = 10)

desig_social <- dfm(desig_social, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

desig_social <- dfm_wordstem(desig_social, language = "portuguese")
desig_social.tfidf <- dfm_tfidf(desig_social)

```

Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - desigualdade social - termos repetidos}

textplot_wordcloud(desig_social, max_words = 300, rotation = .25)

```

Então, os termos mais específicos

```{r exploracao textual visao categorica - desigualdade social - termos especificos tfidf}

desig_social.especific <- textstat_frequency(desig_social.tfidf, n = 40) 

ggplot(desig_social.especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```


Agora, os collocations:

```{r exploracao textual visao categorica - desigualdade social - collocations}

desg_social_collocations <- tokens(amostra_aleatoria)
desg_social_collocations <- tokens_select(desg_social_collocations, pattern = dicionario_fase1[["desigualdade_social"]], case_insensitive = TRUE, window = 10)

desg_social_collocations <- textstat_collocations(desg_social_collocations, size = 3, min_count = 3, tolower = TRUE)

desg_social_collocations <- as.data.frame(desg_social_collocations)
desg_social_collocations <- desg_social_collocations[1:40,]

ggplot(desg_social_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```


Por último, os nomes próprios:


```{r exploracao textual visao categorica - desigualdade social - nomes próprios}

nomes_prop_desg_social <- tokens(amostra_aleatoria)
nomes_prop_desg_social <- tokens_select(nomes_prop_desg_social, pattern = dicionario_fase1[["desigualdade_social"]], case_insensitive = TRUE, window = 10)

nomes_prop_desg_social <-tokens_remove(nomes_prop_desg_social, stopwords("portuguese"), padding = TRUE)

nomes_prop_desg_social <- tokens_select(nomes_prop_desg_social, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_desg_social <- textstat_collocations(nomes_prop_desg_social, size = 2, tolower = FALSE)

ggplot(nomes_prop_desg_social, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - desigualdade social - kwic}

desg_social_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["desigualdade_social"]]), case_insensitive = TRUE, window = 10)

```

Agora, passemos para categoria "Meio Ambiente":


```{r exploracao textual visao categorica - meio ambiente}

meio_amb <- tokens(amostra_aleatoria)
meio_amb <- tokens_select(meio_amb, pattern = dicionario_fase1[["meio_ambiente"]], case_insensitive = TRUE, window = 10)

meio_amb <- dfm(meio_amb, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

meio_amb <- dfm_wordstem(meio_amb, language = "portuguese")
meio_amb.tfidf <- dfm_tfidf(meio_amb)

```

Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - meio ambiente - termos repetidos}

textplot_wordcloud(meio_amb, max_words = 300, rotation = .25)

```


Então, os termos mais específicos


```{r exploracao textual visao categorica - meio ambiente - termos especificos tfidf}

meio_amb.especific <- textstat_frequency(meio_amb.tfidf, n = 40) 

ggplot(meio_amb.especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - meio ambiente - collocations}

meio_amb_collocations <- tokens(amostra_aleatoria)
meio_amb_collocations <- tokens_select(meio_amb_collocations, pattern = dicionario_fase1[["meio_ambiente"]], case_insensitive = TRUE, window = 10)

meio_amb_collocations <- textstat_collocations(meio_amb_collocations, size = 3, min_count = 3, tolower = TRUE)

meio_amb_collocations <- as.data.frame(meio_amb_collocations)
meio_amb_collocations <- meio_amb_collocations[1:40,]

ggplot(meio_amb_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - meio ambiente - nomes próprios}

nomes_prop_meio_amb <- tokens(amostra_aleatoria)
nomes_prop_meio_amb <- tokens_select(nomes_prop_meio_amb, pattern = dicionario_fase1[["meio_ambiente"]], case_insensitive = TRUE, window = 10)

nomes_prop_meio_amb <-tokens_remove(nomes_prop_meio_amb, stopwords("portuguese"), padding = TRUE)

nomes_prop_meio_amb <- tokens_select(nomes_prop_meio_amb, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_meio_amb <- textstat_collocations(nomes_prop_meio_amb, size = 2, tolower = FALSE)

ggplot(nomes_prop_meio_amb, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - meio ambiente - kwic}

meio_amb_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["meio_ambiente"]]), case_insensitive = TRUE, window = 10)

```

Análise da categoria "Paz e Segurança Internacionais"


```{r exploracao textual visao categorica - paz e seg int}

paz_seg_int <- tokens(amostra_aleatoria)
paz_seg_int <- tokens_select(paz_seg_int, pattern = dicionario_fase1[["paz_seguranca_internacional"]], case_insensitive = TRUE, window = 10)

paz_seg_int <- dfm(paz_seg_int, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

paz_seg_int <- dfm_wordstem(paz_seg_int, language = "portuguese")
paz_seg_int.tfidf <- dfm_tfidf(paz_seg_int)

```

Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - paz e seg int - termos repetidos}

textplot_wordcloud(paz_seg_int, max_words = 300, rotation = .25)

```


Então, os termos mais específicos


```{r exploracao textual visao categorica - paz e seg int - termos especificos tfidf}

paz_seg_int_especific <- textstat_frequency(paz_seg_int.tfidf, n = 40) 

ggplot(paz_seg_int_especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - paz e seg int - collocations}

paz_seg_int_collocations <- tokens(amostra_aleatoria)
paz_seg_int_collocations <- tokens_select(paz_seg_int_collocations, pattern = dicionario_fase1[["paz_seguranca_internacional"]], case_insensitive = TRUE, window = 10)

paz_seg_int_collocations <- textstat_collocations(paz_seg_int_collocations, size = 3, min_count = 3, tolower = TRUE)

paz_seg_int_collocations <- as.data.frame(paz_seg_int_collocations)
paz_seg_int_collocations <- paz_seg_int_collocations[1:40,]

ggplot(paz_seg_int_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - paz e seg int - nomes próprios}

nomes_prop_paz_seg_int <- tokens(amostra_aleatoria)
nomes_prop_paz_seg_int <- tokens_select(nomes_prop_paz_seg_int, pattern = dicionario_fase1[["paz_seguranca_internacional"]], case_insensitive = TRUE, window = 10)

nomes_prop_paz_seg_int <-tokens_remove(nomes_prop_paz_seg_int, stopwords("portuguese"), padding = TRUE)

nomes_prop_paz_seg_int <- tokens_select(nomes_prop_paz_seg_int, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_paz_seg_int <- textstat_collocations(nomes_prop_paz_seg_int, size = 2, tolower = FALSE)

ggplot(nomes_prop_paz_seg_int, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - paz e seg int - kwic}

paz_seg_int_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["paz_seguranca_internacional"]]), case_insensitive = TRUE, window = 10)

```

Análise da categoria "Direitos Humanos e Democracia"


```{r exploracao textual visao categorica - dh e demo}

dh_demo <- tokens(amostra_aleatoria)
dh_demo <- tokens_select(dh_demo, pattern = dicionario_fase1[["direitos_humanos_democracia"]], case_insensitive = TRUE, window = 10)

dh_demo <- dfm(dh_demo, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

dh_demo <- dfm_wordstem(dh_demo, language = "portuguese")
dh_demo.tfidf <- dfm_tfidf(dh_demo)

```


Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - dh e demo - termos repetidos}

textplot_wordcloud(dh_demo, max_words = 300, rotation = .25)

```


Então, os termos mais específicos


```{r exploracao textual visao categorica - dh e demo - termos especificos tfidf}

dh_demo_especific <- textstat_frequency(dh_demo.tfidf, n = 40) 

ggplot(dh_demo_especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - dh e demo - collocations}

dh_demo_collocations <- tokens(amostra_aleatoria)
dh_demo_collocations <- tokens_select(dh_demo_collocations, pattern = dicionario_fase1[["direitos_humanos_democracia"]], case_insensitive = TRUE, window = 10)

dh_demo_collocations <- textstat_collocations(dh_demo_collocations, size = 3, min_count = 3, tolower = TRUE)

dh_demo_collocations <- as.data.frame(dh_demo_collocations)
dh_demo_collocations <- dh_demo_collocations[1:40,]

ggplot(dh_demo_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - dh e demo - nomes próprios}

nomes_prop_dh_demo <- tokens(amostra_aleatoria)
nomes_prop_dh_demo <- tokens_select(nomes_prop_dh_demo, pattern = dicionario_fase1[["direitos_humanos_democracia"]], case_insensitive = TRUE, window = 10)

nomes_prop_dh_demo <-tokens_remove(nomes_prop_dh_demo, stopwords("portuguese"), padding = TRUE)

nomes_prop_dh_demo <- tokens_select(nomes_prop_dh_demo, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_dh_demo <- textstat_collocations(nomes_prop_dh_demo, size = 2, tolower = FALSE)

ggplot(nomes_prop_dh_demo, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - dh e demo - kwic}

dh_demo_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["direitos_humanos_democracia"]]), case_insensitive = TRUE, window = 10)

```


Análise da categoria "Cooperação Internacional"


```{r exploracao textual visao categorica - coop int}

coop_int <- tokens(amostra_aleatoria)
coop_int <- tokens_select(coop_int, pattern = dicionario_fase1[["cooperacao_internacional"]], case_insensitive = TRUE, window = 10)

coop_int <- dfm(coop_int, tolower = TRUE, remove = c(stopwords(language = "portuguese"), "é"), remove_punct = TRUE)

coop_int <- dfm_wordstem(coop_int, language = "portuguese")
coop_int.tfidf <- dfm_tfidf(coop_int)

```


Primeiro, os termos mais repetidos:

```{r exploracao textual visao categorica - coop int - termos repetidos}

textplot_wordcloud(coop_int, max_words = 300, rotation = .25)

```


Então, os termos mais específicos


```{r exploracao textual visao categorica - coop int - termos especificos tfidf}

coop_int_especific <- textstat_frequency(coop_int.tfidf, n = 40) 

ggplot(coop_int_especific, aes(x=reorder(feature, frequency), y=frequency)) + geom_point(shape = 20, size = 2) + coord_flip() + geom_segment(aes(x=feature, y = frequency, xend = feature, yend =0)) + theme_calc() + theme(axis.title = element_blank(), axis.text = element_text(size = rel(1)))

```

Agora, os collocations:

```{r exploracao textual visao categorica - coop int - collocations}

coop_int_collocations <- tokens(amostra_aleatoria)
coop_int_collocations <- tokens_select(coop_int_collocations, pattern = dicionario_fase1[["cooperacao_internacional"]], case_insensitive = TRUE, window = 10)

coop_int_collocations <- textstat_collocations(coop_int_collocations, size = 3, min_count = 3, tolower = TRUE)

coop_int_collocations <- as.data.frame(coop_int_collocations)
coop_int_collocations <- coop_int_collocations[1:40,]

ggplot(coop_int_collocations, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Por último, os nomes próprios:


```{r exploracao textual visao categorica - coop int - nomes próprios}

nomes_prop_coop_int <- tokens(amostra_aleatoria)
nomes_prop_coop_int <- tokens_select(nomes_prop_coop_int, pattern = dicionario_fase1[["cooperacao_internacional"]], case_insensitive = TRUE, window = 10)

nomes_prop_coop_int <-tokens_remove(nomes_prop_coop_int, stopwords("portuguese"), padding = TRUE)

nomes_prop_coop_int <- tokens_select(nomes_prop_coop_int, "^([A-Z][a-z\\-]{2,})", valuetype = "regex", case_insensitive = FALSE, padding = TRUE)

nomes_prop_coop_int <- textstat_collocations(nomes_prop_coop_int, size = 2, tolower = FALSE)

ggplot(nomes_prop_coop_int, aes(x=reorder(collocation, count), y=count)) + geom_col() + coord_flip()

```

Passemos, então, para a produção da lista de KWIC: 

```{r exploracao textual visao categorica - coop int - kwic}

coop_int_kwic <- kwic(amostra_aleatoria, pattern = phrase(dicionario_fase1[["cooperacao_internacional"]]), case_insensitive = TRUE, window = 10)

```


# 9. Observações Finais e Informações

Essa é uma seção conclusiva. Termina, aqui, a primeira fase da pesquisa. O dicionário final está disponível em um arquivo YML em uma pasta separada. Acerca disso, é necessário salientar que, na referida pasta, também estarão presentes documentos que informam melhor como se deu toda a montagem do dicionário, a mesma ocorreu de um modo teórico-dedutivo e empírico-indutivo. Quanto à parte empírica-indutiva, ela se inspira nos resultados aqui gerados e que podem facilmente replicados através desse script. 

  






